par(family = "HiraKakuProN-W3")
# read file
filename = "average_scores"
df <- read.csv(file = paste(filename, ".csv", sep=""),
fileEncoding = "utf-8",
header = T)
# define columns to remove
column_remove <- c("X", "リスニング")
# remove unnecessary columns
df <- df[, -which(colnames(df) %in% column_remove)]
# regularize
df <- data.frame(scale(df))
# number of observation
n_row <- nrow(df)
# split into train and test data
df_train <- df[1:n_row-1,]
df_test <- df[n_row,]
# number of observation
n_row_train <- nrow(df_train)
# sample covariance matrix
omega <- cov(df_train)
#####################################
# get optimal rho
#####################################
n_iter <- 101
rho <- seq(0.00, 1.00, length=n_iter)
bic <- rho
for(i in 1:n_iter){
tmp_model <- glasso(omega, rho[i], nobs=n_row_train)
p_off_d <- sum(tmp_model$wi != 0 & col(omega) < row(omega))
bic[i] <- -2*(tmp_model$loglik) + p_off_d*log(n_row_train)
}
index_best <- which.min(bic)
rho_and_bic <- data.frame(rho, bic)
gp <- ggplot(rho_and_bic, aes(x=rho, y=bic))
gp <- gp + geom_point()
plot(gp)
#####################################
# draw networks
#####################################
#gmodel <- glasso(omega, rho[index_best], nobs=n_row_train)
gmodel <- glasso(omega, 0.0, nobs=n_row_train)
P <- gmodel$wi %>% round(4)
diag(P) <- 0
colnames(P) <- colnames(df_train)
qgraph_plot <- qgraph(
P,
layout = "circle",
theme = "Borkulo",
edge.labels = T,
nodeNames = names(P[,1]),
filename = filename,
filetype = "pdf",
height = 20,
width = 20,
)
output <- gmodel$w
colnames(output) <- colnames(df_train)
write.csv(output, file=paste(filename, "_w.csv", sep=""))
output <- gmodel$wi
colnames(output) <- colnames(df_train)
write.csv(output, file=paste(filename, "_wi.csv", sep=""))
output <- omega
colnames(output) <- colnames(df_train)
write.csv(output, file=paste(filename, "_s.csv", sep=""))
df
col(omega)
col(omega) < row(omega)
omega
df_train
df_test
library(dplyr)
library(GGally)
library(ggplot2)
library(glasso)
library(qgraph)
# japanize
par(family = "HiraKakuProN-W3")
# read file
filename = "average_scores"
df <- read.csv(file = paste(filename, ".csv", sep=""),
fileEncoding = "utf-8",
header = T)
# define columns to remove
column_remove <- c("X", "リスニング")
# remove unnecessary columns
df <- df[, -which(colnames(df) %in% column_remove)]
# regularize
df <- data.frame(scale(df))
# number of observation
n_row <- nrow(df)
# split into train and test data
df_train <- df[1:n_row-1,]
df_test <- df[n_row,]
# number of observation
n_row_train <- nrow(df_train)
# sample covariance matrix
omega <- cov(df_train)
#####################################
# get optimal rho
#####################################
n_iter <- 101
rho <- seq(0.00, 1.00, length=n_iter)
bic <- rho
for(i in 1:n_iter){
tmp_model <- glasso(omega, rho[i], nobs=n_row_train, thr=1.0e-6)
p_off_d <- sum(tmp_model$wi != 0 & col(omega) < row(omega))
bic[i] <- -2*(tmp_model$loglik) + p_off_d*log(n_row_train)
}
index_best <- which.min(bic)
rho_and_bic <- data.frame(rho, bic)
gp <- ggplot(rho_and_bic, aes(x=rho, y=bic))
gp <- gp + geom_point()
plot(gp)
#####################################
# draw networks
#####################################
#gmodel <- glasso(omega, rho[index_best], nobs=n_row_train)
gmodel <- glasso(omega, 0.0, nobs=n_row_train)
P <- gmodel$wi %>% round(4)
diag(P) <- 0
colnames(P) <- colnames(df_train)
qgraph_plot <- qgraph(
P,
layout = "circle",
theme = "Borkulo",
edge.labels = T,
nodeNames = names(P[,1]),
filename = filename,
filetype = "pdf",
height = 20,
width = 20,
)
output <- gmodel$w
colnames(output) <- colnames(df_train)
write.csv(output, file=paste(filename, "_w.csv", sep=""))
output <- gmodel$wi
colnames(output) <- colnames(df_train)
write.csv(output, file=paste(filename, "_wi.csv", sep=""))
output <- omega
colnames(output) <- colnames(df_train)
write.csv(output, file=paste(filename, "_s.csv", sep=""))
plot(gp)
library(dplyr)
library(GGally)
library(ggplot2)
library(glasso)
library(qgraph)
# japanize
par(family = "HiraKakuProN-W3")
# read file
filename = "average_scores"
df <- read.csv(file = paste(filename, ".csv", sep=""),
fileEncoding = "utf-8",
header = T)
# define columns to remove
column_remove <- c("X", "リスニング")
# remove unnecessary columns
df <- df[, -which(colnames(df) %in% column_remove)]
# regularize
df <- data.frame(scale(df))
# number of observation
n_row <- nrow(df)
# split into train and test data
df_train <- df[1:n_row-1,]
df_test <- df[n_row,]
# number of observation
n_row_train <- nrow(df_train)
# sample covariance matrix
omega <- cov(df_train)
#####################################
# get optimal rho
#####################################
n_iter <- 101
rho <- seq(0.00, 1.00, length=n_iter)
bic <- rho
for(i in 1:n_iter){
tmp_model <- glasso(omega, rho[i], nobs=n_row_train, thr=1.0e-6)
p_off_d <- sum(tmp_model$wi != 0 & col(omega) < row(omega))
print(tmp_model$loglik, p_off_d, log(n_row_train))
bic[i] <- -2*(tmp_model$loglik) + p_off_d*log(n_row_train)
}
index_best <- which.min(bic)
rho_and_bic <- data.frame(rho, bic)
gp <- ggplot(rho_and_bic, aes(x=rho, y=bic))
gp <- gp + geom_point()
plot(gp)
#####################################
# draw networks
#####################################
#gmodel <- glasso(omega, rho[index_best], nobs=n_row_train)
gmodel <- glasso(omega, 0.0, nobs=n_row_train)
P <- gmodel$wi %>% round(4)
diag(P) <- 0
colnames(P) <- colnames(df_train)
qgraph_plot <- qgraph(
P,
layout = "circle",
theme = "Borkulo",
edge.labels = T,
nodeNames = names(P[,1]),
filename = filename,
filetype = "pdf",
height = 20,
width = 20,
)
output <- gmodel$w
colnames(output) <- colnames(df_train)
write.csv(output, file=paste(filename, "_w.csv", sep=""))
output <- gmodel$wi
colnames(output) <- colnames(df_train)
write.csv(output, file=paste(filename, "_wi.csv", sep=""))
output <- omega
colnames(output) <- colnames(df_train)
write.csv(output, file=paste(filename, "_s.csv", sep=""))
library(dplyr)
library(GGally)
library(ggplot2)
library(glasso)
library(qgraph)
# japanize
par(family = "HiraKakuProN-W3")
# read file
filename = "average_scores"
df <- read.csv(file = paste(filename, ".csv", sep=""),
fileEncoding = "utf-8",
header = T)
# define columns to remove
column_remove <- c("X", "リスニング")
# remove unnecessary columns
df <- df[, -which(colnames(df) %in% column_remove)]
# regularize
df <- data.frame(scale(df))
# number of observation
n_row <- nrow(df)
# split into train and test data
df_train <- df[1:n_row-1,]
df_test <- df[n_row,]
# number of observation
n_row_train <- nrow(df_train)
# sample covariance matrix
omega <- cov(df_train)
#####################################
# get optimal rho
#####################################
n_iter <- 101
rho <- seq(0.00, 1.00, length=n_iter)
bic <- rho
for(i in 1:n_iter){
tmp_model <- glasso(omega, rho[i], nobs=n_row_train, thr=1.0e-6)
p_off_d <- sum(tmp_model$wi != 0 & col(omega) < row(omega))
print(tmp_model$loglik, p_off_d, log(n_row_train))
bic[i] <- -2*(tmp_model$loglik) + p_off_d*log(n_row_train)
}
index_best <- which.min(bic)
library(dplyr)
library(GGally)
library(ggplot2)
library(glasso)
library(qgraph)
# japanize
par(family = "HiraKakuProN-W3")
# read file
filename = "average_scores"
df <- read.csv(file = paste(filename, ".csv", sep=""),
fileEncoding = "utf-8",
header = T)
# define columns to remove
column_remove <- c("X", "リスニング")
# remove unnecessary columns
df <- df[, -which(colnames(df) %in% column_remove)]
# regularize
df <- data.frame(scale(df))
# number of observation
n_row <- nrow(df)
# split into train and test data
df_train <- df[1:n_row-1,]
df_test <- df[n_row,]
# number of observation
n_row_train <- nrow(df_train)
# sample covariance matrix
omega <- cov(df_train)
#####################################
# get optimal rho
#####################################
n_iter <- 101
rho <- seq(0.00, 1.00, length=n_iter)
bic <- rho
for(i in 1:n_iter){
tmp_model <- glasso(omega, rho[i], nobs=n_row_train, thr=1.0e-6)
p_off_d <- sum(tmp_model$wi != 0 & col(omega) < row(omega))
#print(tmp_model$loglik, p_off_d, log(n_row_train))
bic[i] <- -2*(tmp_model$loglik) + p_off_d*log(n_row_train)
}
index_best <- which.min(bic)
library(dplyr)
library(GGally)
library(ggplot2)
library(glasso)
library(qgraph)
# japanize
par(family = "HiraKakuProN-W3")
# read file
filename = "average_scores"
df <- read.csv(file = paste(filename, ".csv", sep=""),
fileEncoding = "utf-8",
header = T)
# define columns to remove
column_remove <- c("X", "リスニング")
# remove unnecessary columns
df <- df[, -which(colnames(df) %in% column_remove)]
# regularize
df <- data.frame(scale(df))
# number of observation
n_row <- nrow(df)
# split into train and test data
df_train <- df[1:n_row-1,]
df_test <- df[n_row,]
# number of observation
n_row_train <- nrow(df_train)
# sample covariance matrix
omega <- cov(df_train)
#####################################
# get optimal rho
#####################################
n_iter <- 101
rho <- seq(0.00, 1.00, length=n_iter)
bic <- rho
for(i in 1:n_iter){
tmp_model <- glasso(omega, rho[i], nobs=n_row_train, thr=1.0e-6)
p_off_d <- sum(tmp_model$wi != 0 & col(omega) < row(omega))
#print(tmp_model$loglik, p_off_d, log(n_row_train))
bic[i] <- -2*(tmp_model$loglik) + p_off_d*log(n_row_train)
}
index_best <- which.min(bic)
rho_and_bic <- data.frame(rho, bic)
gp <- ggplot(rho_and_bic, aes(x=rho, y=bic))
gp <- gp + geom_point()
plot(gp)
#####################################
# draw networks
#####################################
#gmodel <- glasso(omega, rho[index_best], nobs=n_row_train)
gmodel <- glasso(omega, 0.0, nobs=n_row_train)
P <- gmodel$wi %>% round(4)
diag(P) <- 0
colnames(P) <- colnames(df_train)
qgraph_plot <- qgraph(
P,
layout = "circle",
theme = "Borkulo",
edge.labels = T,
nodeNames = names(P[,1]),
filename = filename,
filetype = "pdf",
height = 20,
width = 20,
)
output <- gmodel$w
colnames(output) <- colnames(df_train)
write.csv(output, file=paste(filename, "_w.csv", sep=""))
output <- gmodel$wi
colnames(output) <- colnames(df_train)
write.csv(output, file=paste(filename, "_wi.csv", sep=""))
output <- omega
colnames(output) <- colnames(df_train)
write.csv(output, file=paste(filename, "_s.csv", sep=""))
library(dplyr)
library(GGally)
library(ggplot2)
library(glasso)
library(qgraph)
# japanize
par(family = "HiraKakuProN-W3")
# read file
filename = "average_scores"
df <- read.csv(file = paste(filename, ".csv", sep=""),
fileEncoding = "utf-8",
header = T)
# define columns to remove
column_remove <- c("X", "リスニング")
# remove unnecessary columns
df <- df[, -which(colnames(df) %in% column_remove)]
# regularize
df <- data.frame(scale(df))
# number of observation
n_row <- nrow(df)
# split into train and test data
df_train <- df[1:n_row-1,]
df_test <- df[n_row,]
# number of observation
n_row_train <- nrow(df_train)
# sample covariance matrix
omega <- cov(df_train)
#####################################
# get optimal rho
#####################################
n_iter <- 91
rho <- seq(0.1, 1.00, length=n_iter)
bic <- rho
for(i in 1:n_iter){
tmp_model <- glasso(omega, rho[i], nobs=n_row_train, thr=1.0e-6)
p_off_d <- sum(tmp_model$wi != 0 & col(omega) < row(omega))
#print(tmp_model$loglik, p_off_d, log(n_row_train))
bic[i] <- -2*(tmp_model$loglik) + p_off_d*log(n_row_train)
}
index_best <- which.min(bic)
rho_and_bic <- data.frame(rho, bic)
gp <- ggplot(rho_and_bic, aes(x=rho, y=bic))
gp <- gp + geom_point()
plot(gp)
#####################################
# draw networks
#####################################
#gmodel <- glasso(omega, rho[index_best], nobs=n_row_train)
gmodel <- glasso(omega, 0.0, nobs=n_row_train, thr=1.0e-6)
P <- gmodel$wi %>% round(4)
diag(P) <- 0
colnames(P) <- colnames(df_train)
qgraph_plot <- qgraph(
P,
layout = "circle",
theme = "Borkulo",
edge.labels = T,
nodeNames = names(P[,1]),
filename = filename,
filetype = "pdf",
height = 20,
width = 20,
)
output <- gmodel$w
colnames(output) <- colnames(df_train)
write.csv(output, file=paste(filename, "_w.csv", sep=""))
output <- gmodel$wi
colnames(output) <- colnames(df_train)
write.csv(output, file=paste(filename, "_wi.csv", sep=""))
output <- omega
colnames(output) <- colnames(df_train)
write.csv(output, file=paste(filename, "_s.csv", sep=""))
library(dplyr)
library(GGally)
library(ggplot2)
library(glasso)
library(qgraph)
# japanize
par(family = "HiraKakuProN-W3")
# read file
filename = "average_scores"
df <- read.csv(file = paste(filename, ".csv", sep=""),
fileEncoding = "utf-8",
header = T)
# define columns to remove
column_remove <- c("X", "リスニング")
# remove unnecessary columns
df <- df[, -which(colnames(df) %in% column_remove)]
# regularize
df <- data.frame(scale(df))
# number of observation
n_row <- nrow(df)
# split into train and test data
df_train <- df[1:n_row-1,]
df_test <- df[n_row,]
# number of observation
n_row_train <- nrow(df_train)
# sample covariance matrix
omega <- cov(df_train)
#####################################
# get optimal rho
#####################################
n_iter <- 91
rho <- seq(0.1, 1.00, length=n_iter)
bic <- rho
for(i in 1:n_iter){
tmp_model <- glasso(omega, rho[i], nobs=n_row_train, thr=1.0e-6)
p_off_d <- sum(tmp_model$wi != 0 & col(omega) < row(omega))
#print(tmp_model$loglik, p_off_d, log(n_row_train))
bic[i] <- -2*(tmp_model$loglik) + p_off_d*log(n_row_train)
}
index_best <- which.min(bic)
rho_and_bic <- data.frame(rho, bic)
gp <- ggplot(rho_and_bic, aes(x=rho, y=bic))
gp <- gp + geom_point()
plot(gp)
#####################################
# draw networks
#####################################
gmodel <- glasso(omega, rho[index_best], nobs=n_row_train, thr=1.0e-6)
#gmodel <- glasso(omega, 0.0, nobs=n_row_train, thr=1.0e-6)
P <- gmodel$wi %>% round(4)
diag(P) <- 0
colnames(P) <- colnames(df_train)
qgraph_plot <- qgraph(
P,
layout = "circle",
theme = "Borkulo",
edge.labels = T,
nodeNames = names(P[,1]),
filename = filename,
filetype = "pdf",
height = 20,
width = 20,
)
output <- gmodel$w
colnames(output) <- colnames(df_train)
write.csv(output, file=paste(filename, "_w.csv", sep=""))
output <- gmodel$wi
colnames(output) <- colnames(df_train)
write.csv(output, file=paste(filename, "_wi.csv", sep=""))
output <- omega
colnames(output) <- colnames(df_train)
write.csv(output, file=paste(filename, "_s.csv", sep=""))
gmodel$wi
